---
layout:     post   				    # 使用的布局（不需要改）
title:      关于python爬虫的笔记（持续更新） 				# 标题 
subtitle:   爬虫 #副标题
date:       2020-10-13 				# 时间
author:     HHN				        # 作者
header-img: img/post-bg-debug.png 	#这篇文章标题背景图片
catalog: true 						# 是否归档
tags:								#标签
    - 学习
---

## 嗨
>这是我的第一篇学习博客。

# 1 爬虫基本知识：
爬虫的基本通用模板：
```python
"""
这个通用代码框架常用来处理request网页时发生的各种异常
"""
import requests
def getHTMLInner(url):
	try:
		r = requests.get(url, timeout(30))
		# 设置最长时间30s
		r.raise_for_status()
		# 如果连接正常返回值为200，如果异常则会抛出错误，也可以写if语句而不是用try
		r.encoding = r.appearent_encoding
		# 避免编码出现异常
	except:
		print("出现异常")		
if __name__ == "__main__":
	# 以百度为例
	url = "www.baidu.com"
	print(getHTMLInner(url))
```
    
一个网站反爬的两个方法：一：检查来源  二：robots user-agent代表哪些爬虫，disallow代表什么东西不能爬

所以通常反爬的方法是：

		    1.设置robot不爬robot协定不让爬的内容
		    
		    2.设置header，由于有些网站的反爬手段比较强，所以需要我们构造多个header
		    
		    利用random库里的random.choice方法随机选择一个header，构造header的方法有
		    
		    直接使用fakeheader库或者自己收集

# 2 爬虫常用库：
   2.1 beautifulsoup库:
   
beautifulsoup库是解析维护遍历标签树的库

基本使用python标准库即（html, "html.parser"）

bs4库的几种基本元素tag name attrs navigablestring comment

以获取navigabliestring为例soup.a.string即可获取

soup.find方法和find_all方法的参数(表1.1):

|  参数   | 说明  |
|  ----  | ----  |
|  name	 | 对标签名称的检索字符串 |
| recursive  | 是否对子孙全部检索，默认True |
| string  | …/中字符串区域的检索字符串 |
| **kwargs | 控制参数，上面已经提过，不再赘述 |

（表1.1）
